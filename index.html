---
layout: page
title: Trojan Detection Challenge
background: '/img/bg-trojan.png'
---

<p>In this competition, we challenge you to detect and analyze Trojan attacks on deep neural networks that are <b>designed to be difficult to detect</b>. Neural network Trojans are a growing concern for the security of ML systems, but little is known about the fundamental offense-defense balance of Trojan detection. Early work suggests that standard Trojan attacks may be easy to detect [cite], but recently it has been shown that in simple cases one can design practically undetectable Trojans [cite]. We invite you to help answer an important research question for deep neural networks: How hard is it to detect hidden functionality that is trying to stay hidden?</p>

<p><b>Prizes:</b> There is a <u>$50,000 prize pool.</u> The winning teams will also be invited to co-author a publication summarizing the competition results.</p>


<h2>Overview</h2>

<p>How hard is neural network Trojan detection? Participants will help answer this question in three complementary tracks:</p>
<ol>
  <li><b>Trojan Detection Track:</b> Given a dataset of Trojaned and clean networks spanning multiple data sources, build a Trojan detector that classifies a test set of networks with held-out labels (Trojan, clean).</li>
  <li><b>Trojan Analysis Track:</b> Given a dataset of Trojaned networks spanning multiple data sources, predict various properties of Trojaned networks on a test set with held-out labels. This track has two subtracks: (1) predicting the target label of an attack, (2) reverse-engineering the trigger location and shape.</li>
  <li><b>Evasive Trojans Track:</b> Given a dataset of clean networks and a list of attack specifications including desired performance level, train a small set of Trojaned networks and upload them to the evaluation server. The server will verify that the attack specifications are met, then train and evaluate a baseline Trojan detector using held-out clean networks and the submitted Trojaned networks. The task is to create Trojaned networks that are hard to detect.</li>
</ol>

<p>The competition has two rounds: In the first round, participants will compete on a dataset of over 6,000 neural networks compromised by Trojan attacks that are designed to be hard to detect. Along with detecting Trojans, participants will also create their own evasive Trojans to be tested against a state-of-the-art Trojan detector. In the second and final round, the solution of the first-place team in the Evasive Trojans track will be used to train a new set of hard-to-detect Trojans, and participants will compete to detect these networks.</p>


<h2>Rules</h2>
<ol>
  <li><b>Open Format:</b> This is an open competition. All participants are encouraged to share their methods upon conclusion of the competition, and outstanding submissions will be highlighted in a joint publication. To be eligible for prizes, winning teams are required to share their methods, code, and models (at least with the organizers, although public releases are encouraged).</li>
  <li><b>Registration:</b> This is an open competition. All participants are encouraged to share their methods upon conclusion of the competition, and outstanding submissions will be highlighted in a joint publication. To be eligible for prizes, winning teams are required to share their methods, code, and models (at least with the organizers, although public releases are encouraged).</li>
  <li><b>Training Data:</b> Teams may only submit results of models trained on the provided training set of Trojaned and clean networks. Training additional networks from scratch is not allowed, as it gives teams with more compute an unfair advantage.</li>
  <li><b>Detection Methods:</b> Augmentation of the provided dataset of neural networks is allowed as long as it does not involve training additional networks from scratch. Using inputs from the data sources (e.g., MNIST, CIFAR-10, etc.) is allowed.</li>
  <li><b>Rule breaking</b> may result in disqualification, and significant rule breaking will result in an ineligibility for prizes.</li>
</ol>
<p>These rules are an initial set, and we require participants to consent
to a change of rules if there is an urgent need during registration. If a situation should arise that was
not anticipated, we will implement a fair solution, ideally using consensus of participants.</p>

<h2>Organizers</h2>

<div class="wrapper">
  <div class="grid">
    <div class="grid-item">
      <figure>
        <img src="https://unsplash.it/250/187?image=400" alt="">
        <figcaption>Mantas Mazeika (UIUC)</figcaption>
      </figure>
    </div>
    <div class="grid-item">
      <a href="https://people.eecs.berkeley.edu/~hendrycks/" target="_blank">
        <figure>
          <img src="/img/people/hendrycks.jpeg" alt="">
          <figcaption>Dan Hendrycks (UC Berkeley)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="http://huichenli.net/" target="_blank">
        <figure>
          <img src="/img/people/hli.jpeg" alt="">
          <figcaption>Huichen Li (UIUC)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="https://scholar.google.com/citations?user=rdMZZQwAAAAJ" target="_blank">
        <figure>
          <img src="/img/people/xu.jpeg" alt="">
          <figcaption>Xiaojun Xu (UIUC)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="https://shough.me/" target="_blank">
        <figure>
          <img src="/img/people/hough.png" alt="">
          <figcaption>Sidney Hough (Stanford)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="https://rajabia.github.io/" target="_blank">
        <figure>
          <img src="/img/people/rajabi.png" alt="">
          <figcaption>Arezoo Rajabi (UW)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="https://people.eecs.berkeley.edu/~dawnsong/" target="_blank">
        <figure>
          <img src="/img/people/song.jpeg" alt="">
          <figcaption>Dawn Song (UC Berkeley)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="https://people.ece.uw.edu/radha/index.html" target="_blank">
        <figure>
          <img src="/img/people/poovendran.jpeg" alt="">
          <figcaption>Radha Poovendran (UW)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="https://aisecure.github.io/" target="_blank">
        <figure>
          <img src="/img/people/bli.jpeg" alt="">
          <figcaption>Bo Li (UIUC)</figcaption>
        </figure>
      </a>
    </div>
    <div class="grid-item">
      <a href="http://luthuli.cs.uiuc.edu/~daf/">
        <figure>
          <img src="/img/people/forsyth.png" alt="">
          <figcaption>David Forsyth (UIUC)</figcaption>
        </figure>
      </a>
    </div>
  </div>
</div>

<p>Contact: <a href="mailto:tdc-organizers@googlegroups.com">tdc-organizers@googlegroups.com</a></p>
<p>We are sponsored by the FTX Future Fund.</p>